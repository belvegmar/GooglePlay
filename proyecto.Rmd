---
title: "GooglePlay"
author: "Belen_Miguel"
date: "18 de diciembre de 2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
#install.packages(c("plyr"))
library("plyr")
library("tidyr")
library("ggplot2")
library("GGally")
library("plotly")
```

# Lectura de los datos
```{r cars}
datos <- read.csv(file="googleplaystore.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)

```

```{r}
num <- c(1:10841)
apps <- c(datos$Category)
number_of_apps <- data.frame(num, apps)
```


# Echamos un vistazo al dataset
```{r}
str(datos)

```

# Limpieza de datos y transformación
El primer paso será hacer un preprocesamiento de cada uno de los atributos con vista a obtener mejores resultados en los algoritmos de minería de datos

## Size
Se puede obsrevar que los datos del tamaño de las aplicaciones tienen prefijos métricos (Kilo y Mega). Para poder hacer un análisis de datos efectivo, se eliminarán estos símbolos por sus correspondientes equivalencias numéricas.
Además de estos símbolos hay apps cuyo tamaño varían con el dispositivo ("Varies with devices"), estos ejemplos se sustituirán por valores nulos. Por otro lado, también hay instancias que tienen como valor "1000+", estas se sustituirán por 1000. En resumen, las tareas que se van a realizar son las siguientes:

* Reemplazar "Varies with devices" por NaN
* Convertir k y M a numérico
* Pasar 1.000+ a 1000 para hacerlo numérico
* Los valores NaN se sustituyen por la media de la columna

```{r}
for (i in 1:length(datos$Size)) { 
  if(grepl("M",datos$Size[i])){
    numero <- as.numeric(gsub("M", "e+06", datos$Size[i]))
    datos$Size[i]<- numero
  } else if (grepl("k", datos$Size[i])){
    numero <- as.numeric(gsub("k", "e+03", datos$Size[i]))
    datos$Size[i] <- numero
  }else if (grepl("Varies", datos$Size[i])){
    datos$Size[i] <- NaN
  }else{
    datos$Size[i]<-1000
  }
}

datos$Size <- as.numeric(datos$Size)
datos$Size[is.na(datos$Size)] <- mean(datos$Size, na.rm=TRUE)
```

## Installs
Convertir "Installs" en numeric
Removemos el simbolo (+) y luego convertimos a numérico. Comprobamos los cambios.

```{r, warning=FALSE}
datos$Installs <- as.numeric(gsub(",", "", gsub("+", "", datos$Installs, fixed = TRUE), fixed=TRUE))
options("scipen"=100, "digits"=4)
str(datos$Installs)
print(unique(datos$Installs))
##Convertir Nan en 0 porque el Nan viene de una app que es Free
for (i in 1:length(datos$Installs)) { 
  if(is.na(datos$Installs[i])){
    datos$Installs[i]<-0
  }
}


```

## Reviews 
Comprobaremos si los valores del atributo "Reviews" son de tipo numérico:
```{r, warning=FALSE}
datos$Reviews <- as.numeric(datos$Reviews)
print(sum(is.na(datos$Reviews)))
```

Se puede observar que al convertir la columna a número, un valor no se ha podido convertir, ya que no había forma. Daremos un vistazo previo a esta fila:
```{r}
for (i in 1:length(datos$Reviews)) {
  if(is.na(datos$Reviews[i])){
    print(i)
    print(datos[i,])
    datos <- datos[-i,]
    
  }
}


```
Como solo es una fila, se optará por eliminarla directamente. En la representación de arriba se ve cómo ha desaparecido del dataframe.


## Rating 
Se comprueba que los valores están entre 1 y 5. Tiene valores que son NaN, se sustituyen por la media de la columna
```{r}
print(range(datos$Rating, na.rm = TRUE))
datos$Rating[is.na(datos$Rating)] <- mean(datos$Rating, na.rm=TRUE)
```



## Price 
```{r}
print(unique(datos$Price))
```

Se puede observar que la variable precio tiene un carácter $ que hay que eliminar para poder convertirlo en número. Además, hay varias columnas que tienen valores raros ("Everyone"), estas filas las convertiremos en Nan y posteriormente se sustituirá por la media de precios

```{r, warning=FALSE}
for (i in 1:length(datos$Price)){
  datos$Price[i] <- as.numeric((gsub("\\$","", datos$Price[i])))
}

datos$Price[is.na(datos$Price)] <- mean(datos$Price, na.rm=TRUE)
datos$Price <- as.numeric(datos$Price)
#Eliminar valores NAN
# for (i in 1:length(datos$Price)){
#   if(is.na(datos$Price[i])){
#     print(i)
#     print(datos[i,])
#     datos <- datos[-i,]
#     
#   }
# }

```
Lo más curioso es que hay aplicaciones que superan los 350 dólares, tal como se puede ver en el histograma a continuación:
```{r}
hist(datos$Price)

```
```{r}
for (i in 1:length(datos$Price)){
  if(datos$Price[i]>350){
    print(datos$Price[i])
  }
}
```


## Genres
Esta columna tiene algunos datos que están en el formato __Category;Subcategory__ para poder hacer un estudio más exhaustivo, se va a dividir esta columna en dos, por un lado una columna con la Categoría principal y otra con la subcategoría. Luego comprobamos valores unicos.

```{r, warning=FALSE}
head(datos$Genres, n = 50)
datos <-separate(data=datos, col = Genres, into = c("Pri_Genre", "Sec_Genre"), sep = ";")
head(datos$Pri_Genre, n = 50)
head(datos$Sec_Genre) 

```


## Last updated
Convertir la fecha que está en formato String a Date
```{r}
Sys.setlocale("LC_TIME", "C")
datos$Last.Updated <- as.Date(datos$Last.Updated, format = "%B %d, %Y",origin='1970-01-01')
```




## Current version
Convertir versiones a números con el formato número.número
```{r, warning=FALSE}
for (i in 1:length(datos$Current.Ver)){
  if(datos$Current.Ver[i]!="Varies with device"){
    datos$Current.Ver[i]<-as.numeric(substr(as.character(datos$Current.Ver[i]),0,3))
  }
} 
```

Reemplazar los valores nulos con "Varies with device"
```{r}
for (i in 1:length(datos$Current.Ver)){
  if(is.na(datos$Current.Ver[i])){
    datos$Current.Ver[i]<-"Varies with device"
  }
}
```


# Visualización de los datos

##Android Market Breakdown

Aqui veremos cuales de las aplicaciones son mas utilizadas por los usuarios. Para esto tenemos que crear un nuevo data frame con la categoria de aplicaciones mas utilizadas.

```{r}
p <- plot_ly(number_of_apps, labels = ~apps, values = ~num, type = 'pie') %>%
  layout(title = 'Aplicaciones mas utilizadas segun categoria',
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
p


```


## Pairplot
Este tipo de gráficos permite ver si hay alguna relación entre dos o más variables, pudiendo observar si hay una relación directa (cuando una variable crece la otra también) o inversa (cuando una crece, la otra decrece). 
En el siguiente gráfico se presentará este gráfico para las variables numéricas del conjunto de datos

```{r}
columnas_numericas = c("Rating","Reviews", "Size", "Installs", "Price")
ggpairs(datos[columnas_numericas],
        title="Relations in numeric data")
```


Los coeficientes de correlación no están cercanos ni a 1 ni a -1, más bien a cero, lo que significa que ninguna variable está a priori relacionada con otra


## Puntuación media de las aplicaciones
```{r}
sprintf("La media de la puntuación es:   %f", mean(datos$Rating))

p<-ggplot(datos, aes(x=Rating)) + 
  geom_histogram(binwidth = 0.1, fill="red")
p
```
La media de la calificación es de un 4.17, por lo que en general, los usuarios puntúan muy bien las aplicaciones en la Play Store.
Tampoco se ve que haya diferencia de puntuación entre aplicaciones gratuitas y no
```{r}
sprintf("La media de la puntuación de apps Gratuitas es:   %f", mean(datos$Rating[datos$Type=='Free']))

sprintf("La media de la puntuación de apps de Pago es:   %f", mean(datos$Rating[datos$Type!='Free']))
```

## Mejores categorías
```{r, fig.width=10, fig.height=10}
g <- ggplot(datos, aes(datos$Category, datos$Rating)) +
  geom_violin(scale="width") + theme(axis.text.x = element_text(angle = 85, hjust = 1)) + stat_summary(fun.y=mean, geom="point", shape=15, size=1) + scale_color_brewer(palette = "Dark2") + geom_hline(yintercept = mean(datos$Rating), linetype="dashed", color="red", size = 2)
print(g)
```

*Con los puntos negros se observa la media para cada categoría, y la línea roja indica la media de todas las apps. Sabiendo esto, las 3 mejores categorías son __EDUCATION, EVENTS y ART AND DESIGN__ las tres peores son __DATING, TOOLS y VIDEO PLAYERS__


## Estrategia de precios
¿Cómo afecta el precio de las aplicaciones a su puntuación?
```{r}
# library
library(ggplot2)
library(ggExtra)
 
 
# classic plot :
p=ggplot(datos, aes(x=datos$Price, y=datos$Rating)) +
      geom_point() +
      theme(legend.position="none") 
#+ coord_cartesian(xlim=c(0,10))
 
# with marginal histogram
p <- ggMarginal(p, type="density")
 
print(p)


```
La mayoría de aplicaciones más valoradas se encuentran en el rango de precios de 0 a 50 dólares.






# Minería de datos
En esta parte intentaremos aplicar varios métodos de minería de datos para poder sacar conclusiones a partir de los datos. A continuación se exponen los algoritmos que se utilizarán y cuál es su propósito:
* __Regresión Lineal__ : el objetivo de este algoritmo es predecir un valor continuo numérico (variable dependiente Y) según otras variables (variables independientes Xs). En este caso, es interesante predecir el atributo Rating en función de otros.


## Regresión Logística
En primer lugar haremos el modelo con validación train-test 
```{r}
##https://www.analyticsvidhya.com/blog/2014/12/caret-package-stop-solution-building-predictive-models/

#http://r-statistics.co/Linear-Regression.html
library(dummies)
library(caret)

#One hot encoding
datosAu <- dummy.data.frame(datos, names = c("Category", "Type", "Content.Rating", "Pri_Genre"), sep='.')


#Preparar el conjunto de datos eliminando las columnas que no interesan
borrar <- c("App","Category", "Type", "Content.Rating", "Pri_Genre", "Sec_Genre", "Current.Ver", "Android.Ver", "Last.Updated")
datosRegresion <- datosAu[ , !(names(datosAu) %in% borrar)]

#Dividir el conjunto de datos en train y test
set.seed(3456)
trainIndex <- createDataPartition(datosRegresion$Rating, p = .8, 
                                  list = FALSE, 
                                  times = 1)
datosRegresionTrain <- datosRegresion[ trainIndex,]
datosRegresionTest  <- datosRegresion[-trainIndex,]


#Modelo Regresión Lineal Validación Train Test
lmFit<-train(Rating~., data = datosRegresionTrain, method = "lm")
pred <- predict(lmFit, datosRegresionTest)
modelvalues<-data.frame(obs = datosRegresionTest$Rating, pred=pred)


```
Validación Train Test. El p-value (p-value: <0.0000000000000002) es mucho menor que el valor de significancia, por lo que los datos son estadísticamente buenos.
```{r}
summary <- summary(lmFit)
print(defaultSummary(modelvalues))

```

Otra cosa interesante que se puede hacer cuando se tiene un modelo de regresión es ver qué variable influye más en la variable que se quiere predecir, en este caso, se observa que el __tamaño__ de la app influye mucho en la puntuación final de la app, así como que la app sea de citas o no en segundo lugar
```{r}
importancia <- varImp(lmFit)
plot(importancia)
```


En segundo lugar haremos la validación con K-Cross Validation con k = 10
```{r}
ctrl<-trainControl(method = "cv",number = 10)

lmCVFit<-train(Rating ~ ., data = datosRegresion, method = "lm", trControl = ctrl, metric="RMSE")

sum<-summary(lmCVFit)
print(sum$r.squared)
```

Se observa que con CV se obtiene un RSquared mayor, lo que significa que el resultado de la predicción es mejor.